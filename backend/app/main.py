"""
FinKuRN Backend - FastAPI Main Application
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë©”ì´í¬ë¦¬ AI ì›Œí¬í”Œë¡œìš° ì•„í‚¤í…ì²˜ ê¸°ë°˜ ì±—ë´‡ API
- Supervisor Agent â†’ 5ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ â†’ Synthesizer
- FastMCPë¥¼ í†µí•œ Tool ì¶”ìƒí™”
- LangGraphë¥¼ í†µí•œ Multi-Agent ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- Milvus(Vector DB) + Neo4j(Graph DB)
"""

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from loguru import logger
import os
from datetime import datetime

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="FinKuRN AI Backend",
    description="ë©”ì´í¬ë¦¬ AI ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ê¸ˆìœµ ìƒë‹´ ì±—ë´‡",
    version="1.0.0",
)

# CORS ì„¤ì • (React Nativeì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Health Check & Status Endpoints
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ë°˜í™˜"""
    return {
        "service": "FinKuRN AI Backend",
        "version": "1.0.0",
        "status": "running",
        "architecture": "ë©”ì´í¬ë¦¬ AI ì›Œí¬í”Œë¡œìš°",
        "components": {
            "orchestration": "LangGraph",
            "tools": "FastMCP",
            "vector_db": "Milvus",
            "graph_db": "Neo4j",
            "llm": "Claude 3.5 Sonnet (AWS Bedrock)",
        },
        "timestamp": datetime.utcnow().isoformat(),
    }


@app.get("/health")
async def health_check():
    """
    í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
    - Docker healthcheckì—ì„œ ì‚¬ìš©
    - ëª¨ë“  ì˜ì¡´ì„± ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    """
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "services": {},
    }

    # TODO: Milvus ì—°ê²° í™•ì¸
    try:
        # from app.db.milvus_client import check_connection
        # milvus_healthy = check_connection()
        health_status["services"]["milvus"] = "not_implemented"
    except Exception as e:
        health_status["services"]["milvus"] = f"error: {str(e)}"

    # TODO: Neo4j ì—°ê²° í™•ì¸
    try:
        # from app.db.neo4j_client import check_connection
        # neo4j_healthy = check_connection()
        health_status["services"]["neo4j"] = "not_implemented"
    except Exception as e:
        health_status["services"]["neo4j"] = f"error: {str(e)}"

    # ì „ì²´ ìƒíƒœ íŒë‹¨
    if any("error" in str(v) for v in health_status["services"].values()):
        health_status["status"] = "degraded"

    return health_status


@app.get("/api/status")
async def api_status():
    """
    API ìƒíƒœ ìƒì„¸ ì •ë³´
    - í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ë¯¼ê° ì •ë³´ ì œì™¸)
    - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ
    """
    return {
        "api_version": "1.0.0",
        "environment": {
            "anthropic_api_configured": bool(os.getenv("ANTHROPIC_API_KEY")),
            "openai_api_configured": bool(os.getenv("OPENAI_API_KEY")),
            "milvus_host": os.getenv("MILVUS_HOST", "localhost"),
            "neo4j_uri": os.getenv("NEO4J_URI", "bolt://localhost:7687"),
        },
        "features": {
            "chat": "ready",
            "policy_search": "ready",
            "eligibility_check": "ready",
            "graph_inference": "not_implemented",  # Phase 2
            "emotional_analysis": "not_implemented",  # Phase 3
        },
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Chat API Endpoints
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


@app.post("/api/chats/{chat_id}/messages")
async def send_message(chat_id: str, request: Request):
    """
    ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ ì—”ë“œí¬ì¸íŠ¸

    Flow:
    1. ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ì‹ 
    2. LangGraph Workflow ì‹¤í–‰
       - Supervisor Agent: ì˜ë„ íŒŒì•… & ë¼ìš°íŒ…
       - Specialized Agents: ê°ì ì—­í•  ìˆ˜í–‰
       - Synthesizer Agent: ìµœì¢… ì‘ë‹µ ìƒì„±
    3. ì‘ë‹µ ë°˜í™˜

    TODO: ì‹¤ì œ LangGraph ì›Œí¬í”Œë¡œìš° êµ¬í˜„
    """
    try:
        body = await request.json()
        user_message = body.get("message", "")
        user_context = body.get("context", {})

        logger.info(f"Chat {chat_id}: Received message: {user_message}")

        # TODO: LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        # from app.langgraph.graph import run_workflow
        # response = await run_workflow(user_message, user_context)

        # ì„ì‹œ ì‘ë‹µ (êµ¬í˜„ ì™„ë£Œ ì „ê¹Œì§€)
        mock_response = {
            "id": f"msg_{datetime.utcnow().timestamp()}",
            "chatId": chat_id,
            "content": f"[í…ŒìŠ¤íŠ¸ ì‘ë‹µ] ë©”ì‹œì§€ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤: '{user_message}'\n\nì‹¤ì œ LangGraph ì›Œí¬í”Œë¡œìš°ëŠ” ì•„ì§ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤.",
            "role": "assistant",
            "timestamp": datetime.utcnow().isoformat(),
            "metadata": {
                "workflow_status": "not_implemented",
                "agents_triggered": [],
                "tools_used": [],
            },
        }

        return mock_response

    except Exception as e:
        logger.error(f"Error processing message: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": "Internal server error", "detail": str(e)},
        )


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Startup & Shutdown Events
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    logger.info("ğŸš€ FinKuRN AI Backend starting...")
    logger.info("ğŸ“‹ Architecture: ë©”ì´í¬ë¦¬ AI ì›Œí¬í”Œë¡œìš°")
    logger.info("ğŸ”§ Orchestration: LangGraph")
    logger.info("ğŸ› ï¸  Tools: FastMCP")
    logger.info("ğŸ—„ï¸  Vector DB: Milvus")
    logger.info("ğŸ•¸ï¸  Graph DB: Neo4j")

    # TODO: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”
    # await init_milvus()
    # await init_neo4j()


@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    logger.info("ğŸ‘‹ FinKuRN AI Backend shutting down...")
    # TODO: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # ê°œë°œ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©
        log_level="info",
    )
